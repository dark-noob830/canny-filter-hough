{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T13:33:37.511592Z",
     "start_time": "2025-03-28T13:33:37.508825Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the test image\n",
    "\n",
    "Define the identity kernel, using a 3×3 NumPy array\n",
    "\n",
    "Use the filter2D() function in OpenCV to perform the linear filtering operation\n",
    "\n",
    "Display the original and filtered images, using imshow()\n",
    "\n",
    "Save the filtered image to disk, using imwrite()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T13:13:33.959585Z",
     "start_time": "2025-03-28T13:13:32.827012Z"
    }
   },
   "source": [
    "image = cv2.imread('test.jpg')\n",
    "\"\"\"\n",
    "Apply identity kernel\n",
    "\"\"\"\n",
    "kernel1 = np.ones((3,3))/9\n",
    "# filter2D() function can be used to apply kernel to an image.\n",
    "# Where ddepth is the desired depth of final image. ddepth is -1 if...\n",
    "# ... depth is same as original or source image.\n",
    "identity = cv2.filter2D(image, -1, kernel1)\n",
    " \n",
    "# We should get the same image\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Identity', identity)\n",
    " \n",
    "cv2.waitKey()\n",
    "cv2.imwrite('identity.jpg', identity)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will demonstrate how to blur an image. Here too, we will define a custom kernel, and use the filter2D() function in OpenCV to apply the filtering operation on the source image. \n",
    "\n",
    "Begin by defining a 5×5 kernel, consisting of only ones. Note that we also divide the kernel by 25. Why is that? Well, before you apply any convolution to an image, using a 2D-convolution matrix, you need to ensure that all the values are normalized. This is done by dividing each element of the kernel, by the number of elements in the kernel, which in this case is 25. This ensures all values stay within the range of [0,1]. \n",
    "\n",
    "Now use the filter2D() function to filter the image. As you can see, filter2D() can be used to convolve an image, with any user-defined kernel."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T13:13:36.782830Z",
     "start_time": "2025-03-28T13:13:36.043305Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Apply blurring kernel\n",
    "\"\"\"\n",
    "kernel2 = np.ones((5,5))/25\n",
    "img = cv2.filter2D(image, -1, kernel2)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Kernel Blur', img)\n",
    " \n",
    "cv2.waitKey()\n",
    "cv2.imwrite('blur_kernel.jpg', img)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now apply a Gaussian blur to an image, using OpenCV. This technique uses a Gaussian filter, which performs a weighted average, as opposed to the uniform average described in the first example. In this case, the Gaussian blur weights pixel values, based on their distance from the center of the kernel. Pixels further from the center have less influence on the weighted average. The following code convolves an image, using the GaussianBlur() function in OpenCV.\n",
    "\n",
    "GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]])\n",
    "\n",
    "The GaussianBlur() function requires four input arguments:\n",
    "\n",
    "The first argument, src, specifies the source image that you want to filter.\n",
    "The second argument is ksize, which defines the size of the Gaussian kernel. Here, we are using a 5×5 kernel.\n",
    "The final two arguments are sigmaX and sigmaY, which are both set to 0. These are the Gaussian kernel standard deviations, in the X (horizontal) and Y (vertical) direction. The default setting of sigmaY is zero. If you simply  set sigmaX to zero, then the standard deviations are computed from the kernel size (width and height respectively). You can also explicitly set the size of each argument to positive values greater than zero."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T13:13:38.234298Z",
     "start_time": "2025-03-28T13:13:37.885381Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Apply Gaussian blur\n",
    "\"\"\"\n",
    "# sigmaX is Gaussian Kernel standard deviation \n",
    "# ksize is kernel size\n",
    "gaussian_blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "\n",
    " \n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Gaussian Blurred', gaussian_blur)\n",
    "     \n",
    "cv2.waitKey()\n",
    "cv2.imwrite('gaussian_blur.jpg', gaussian_blur)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply median blurring, using the medianBlur() function in OpenCV. In median blurring, each pixel in the source image is replaced by the median value of the image pixels in the kernel area.\n",
    "\n",
    "medianBlur(src, ksize)\n",
    "\n",
    "This function has just two required arguments:\n",
    "\n",
    "The first is the source image.\n",
    "The second is the kernel size, which must be an odd, positive integer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T13:13:39.802501Z",
     "start_time": "2025-03-28T13:13:39.485875Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Apply Median blur\n",
    "\"\"\"\n",
    "# medianBlur() is used to apply Median blur to image\n",
    "# ksize is the kernel size\n",
    "median = cv2.medianBlur(image, 5)\n",
    " \n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Median Blurred', median)\n",
    "     \n",
    "cv2.waitKey()\n",
    "cv2.imwrite('median_blur.jpg', median)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also sharpen an image with a 2D-convolution kernel. First define a custom 2D kernel, and then use the filter2D() function to apply the convolution operation to the image.\n",
    "\n",
    "In the code below, the 3×3 kernel defines a sharpening kernel. Check out this resource to learn more about commonly used kernels."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T13:14:36.946660Z",
     "start_time": "2025-03-28T13:14:35.996866Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Apply sharpening using kernel\n",
    "\"\"\"\n",
    "kernel3 = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "sharp_img = cv2.filter2D(image, -1, kernel3)\n",
    " \n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "cv2.imshow('Sharpened', sharp_img)\n",
    "     \n",
    "cv2.waitKey()\n",
    "cv2.imwrite('sharp_image.jpg', sharp_img)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While blurring can be an effective way to reduce noise in an image, it is often not desirable to blur the entire image, as important details and sharp edges may be lost. In such cases, bilateral filtering can make your life easier.\n",
    "\n",
    "This technique applies the filter selectively to blur similar intensity pixels in a neighborhood. Sharp edges are preserved, wherever possible.\n",
    "It lets you control not only the spatial size of the filter, but also the degree to which the neighboring pixels are included in the filtered output. This is done, based on variation in their color intensity, and also distance from the filtered pixel.\n",
    "Bilateral filtering essentially applies a 2D Gaussian (weighted) blur to the image, while also considering the variation in intensities of neighboring pixels to minimize the blurring near edges (which we wish to preserve). What this means is that the shape of the kernel actually depends on the local image content, at every pixel location.\n",
    "\n",
    "Here’s a concrete example. Assume, you are filtering a region in an image, near an edge. A simple Gaussian blur filter would blur the edge because it lies near the filtered region (close to the center of the Gaussian filter).  But the bilateral filter can sense the edge, because it also considers differences in pixel intensities. So, it will compute a much lower weight for the pixels straddling the edge, thereby reducing their influence on the filtered region. Regions of more uniform intensity are blurred heavier, as they are not associated with strong edges.\n",
    "\n",
    "Thankfully, OpenCV provides the bilateralFilter() function to filter images.\n",
    "\n",
    "bilateralFilter(src, d, sigmaColor, sigmaSpace)\n",
    "\n",
    "This function has four required arguments:\n",
    "\n",
    "The first argument of the function is the source image.\n",
    "The next argument d, defines the diameter of the pixel neighborhood used for filtering.\n",
    "The next two arguments, sigmaColor and sigmaSpace define the standard deviation of the (1D) color-intensity distribution and (2D) spatial distribution respectively.\n",
    "The sigmaSpace parameter defines the spatial extent of the kernel, in both the x and y directions (just like the Gaussian blur filter previously described).\n",
    "The sigmaColor parameter defines the one-dimensional Gaussian distribution, which specifies the degree to which differences in pixel intensity can be tolerated.\n",
    "The final (weighted) value for a pixel in the filtered image is a product of its spatial and intensity weight. Thus,\n",
    "\n",
    "pixels that are similar and near the filtered pixel will have influence\n",
    "pixels that are far away from the filtered pixel will have little influence (due to the spatial Gaussian)\n",
    "pixels that have dissimilar intensities will have little influence (due to the color-intensity Gaussian), even if they are close to the center of the kernel."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T13:15:27.961608Z",
     "start_time": "2025-03-28T13:15:26.461509Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Apply Bilateral Filtering\n",
    "\"\"\"\n",
    "# Using the function bilateralFilter() where d is diameter of each...\n",
    "# ...pixel neighborhood that is used during filtering.\n",
    "# sigmaColor is used to filter sigma in the color space.\n",
    "# sigmaSpace is used to filter sigma in the coordinate space.\n",
    "bilateral_filter = cv2.bilateralFilter(image, 5, 75, 75)\n",
    " \n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Bilateral Filtering', bilateral_filter)\n",
    " \n",
    "cv2.waitKey()\n",
    "cv2.imwrite('bilateral_filtering.jpg', bilateral_filter)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are Edges Detected?\n",
    "Sudden changes in pixel intensity characterize edges. We need to look for such changes in the neighboring pixels to detect edges. Let’s explore using two important edge-detection algorithms available in OpenCV: Sobel Edge Detection and Canny Edge Detection. We will discuss the theory as well as demonstrate the use of each in OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T14:45:16.363010Z",
     "start_time": "2025-03-28T14:40:21.605554Z"
    }
   },
   "source": [
    "import cv2\n",
    " \n",
    "# Read the original image (test2.jpg) # This tiger image will be used for all the examples here. \n",
    "img = cv2.imread('test2.jpg')\n",
    "# Display original image\n",
    "cv2.imshow('Original', img)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# Convert to graycsale\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Blur the image for better edge detection\n",
    "img_blur = cv2.blur(img_gray, (5,5))\n",
    " \n",
    "# Sobel Edge Detection\n",
    "sobelx = cv2.Sobel(img_blur, -1, 1, 0)\n",
    "sobely = cv2.Sobel(img_blur, -1, 0, 1)\n",
    "sobelxy = cv2.Sobel(img_blur, -1, 1, 1)\n",
    "# Display Sobel Edge Detection Images\n",
    "cv2.imshow('Sobel X', sobelx)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel Y', sobely)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel X Y using Sobel() function', sobelxy)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# Canny Edge Detection\n",
    "edges = cv2.Canny(img, 200, 400)\n",
    "# Display Canny Edge Detection Image\n",
    "cv2.imshow('Canny Edge Detection', edges)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the image, we also blur it, using the GaussianBlur() function. This is done to reduce the noise in the image. In edge detection, numerical derivatives of the pixel intensities have to be computed, and this typically results in ‘noisy’ edges. In other words, the intensity of neighboring pixels in an image (especially near edges) can fluctuate quite a bit, giving rise to edges that don’t represent the predominant edge structure we are looking for. \n",
    "\n",
    "Blurring smoothens the intensity variation near the edges, making it easier to identify the predominant edge structure within the image. You can refer to the OpenCV documentation for more details on the GaussianBlur() function. We supply the size of the convolution kernel (in this case, 1 3×3 kernel), which specifies the degree of blurring."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T14:39:53.837534Z",
     "start_time": "2025-03-28T14:39:53.832047Z"
    }
   },
   "source": [
    "# Read the original image\n",
    "img = cv2.imread('test2.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "# Blur the image for better edge detection\n",
    "img_blur = cv2.GaussianBlur(img, (5,5), 0)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T14:40:00.104775Z",
     "start_time": "2025-03-28T14:39:54.247943Z"
    }
   },
   "source": [
    "# Sobel Edge Detection\n",
    "sobelx = cv2.Sobel(img_blur, -1, 1, 0)\n",
    "sobely = cv2.Sobel(img_blur,-1, 0, 1)\n",
    "sobelxy = cv2.Sobel(img_blur, -1, 1, 1)\n",
    " \n",
    "# Display Sobel Edge Detection Images\n",
    "cv2.imshow('Sobel X', sobelx)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "cv2.imshow('Sobel Y', sobely)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "cv2.imshow('Sobel X Y using Sobel() function', sobelxy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T13:38:13.625230Z",
     "start_time": "2025-03-28T13:38:11.434803Z"
    }
   },
   "source": [
    "# Canny Edge Detection\n",
    "edges = cv2.Canny(img, 200, 400)\n",
    " \n",
    "# Display Canny Edge Detection Image\n",
    "cv2.imshow('Canny Edge Detection', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
